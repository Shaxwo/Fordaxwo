{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa29d9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "import random\n",
    "import re\n",
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "# !conda install wordcloud\n",
    "# import wordcloud\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c498213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>263570</th>\n",
       "      <td>???????????????8x4D???????????????????????????...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247926</th>\n",
       "      <td>No issues found on MP2 units.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278677</th>\n",
       "      <td>PCA DCR approved. AIMS pended. Concern to be r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183590</th>\n",
       "      <td>review with jmagill and this does not appear t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206452</th>\n",
       "      <td>System changed from \"PMT 160 - Exterior Trim\" ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              status_text\n",
       "263570  ???????????????8x4D???????????????????????????...\n",
       "247926                      No issues found on MP2 units.\n",
       "278677  PCA DCR approved. AIMS pended. Concern to be r...\n",
       "183590  review with jmagill and this does not appear t...\n",
       "206452  System changed from \"PMT 160 - Exterior Trim\" ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amz=pd.read_csv(\"status text-2018.csv\")\n",
    "amz.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a17deb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({'nobody', 'fill', 'do', 'system', 'there', 'side', 'through', 'next', 'eg', 'thin', 'upon', 'always', 'becoming', 'my', 'still', 'never', 'here', 'both', 'done', 'yet', 'amoungst', 'hers', 'namely', 'whither', 'each', 'first', 'the', 'even', 'her', 'also', 'behind', 'after', 'his', 'otherwise', 'would', 'any', 'now', 'nor', 'whatever', 'herein', 'could', 'onto', 'it', 'its', 'why', 'own', 'several', 'because', 'con', 'cry', 'nowhere', 'though', 'towards', 'beside', 'therefore', 'three', 'enough', 'been', 'at', 'beyond', 'whereupon', 'so', 'above', 'sixty', 'elsewhere', 'hereafter', 'found', 'ours', 'top', 'give', 'name', 'least', 'no', 'yourself', 'become', 'should', 'may', 'made', 'across', 'where', 'hundred', 'into', 'detail', 'thereafter', 'anywhere', 'among', 'together', 'by', 'perhaps', 'de', 'hereupon', 'these', 'couldnt', 'ltd', 'other', 'anyway', 'ourselves', 'can', 'co', 'down', 'amount', 'former', 'call', 'an', 'further', 'neither', 'between', 'nine', 'everyone', 'go', 'a', 'nevertheless', 'else', 'thick', 'fifty', 'all', 'rather', 'besides', 'whenever', 'about', 'have', 'himself', 'then', 'ever', 'back', 'move', 'empty', 'five', 'while', 'none', 'from', 'of', 'in', 'since', 'with', 'one', 'seeming', 'before', 'their', 'anyone', 'be', 'seemed', 're', 'get', 'thence', 'same', 'up', 'something', 'latterly', 'meanwhile', 'your', 'or', 'last', 'latter', 'everything', 'being', 'six', 'nothing', 'however', 'beforehand', 'inc', 'who', 'becomes', 'although', 'whose', 'under', 'us', 'yours', 'not', 'had', 'find', 'such', 'i', 'anyhow', 'either', 'our', 'than', 'ie', 'off', 'and', 'mostly', 'two', 'itself', 'thereupon', 'keep', 'you', 'show', 'twelve', 'another', 'mine', 'anything', 'wherever', 'therein', 'was', 'when', 'most', 'eleven', 'interest', 'someone', 'too', 'more', 'hereby', 'became', 'almost', 'mill', 'eight', 'how', 'along', 'often', 'except', 'put', 'what', 'cannot', 'very', 'but', 'whom', 'everywhere', 'during', 'seem', 'cant', 'again', 'many', 'them', 'whereafter', 'will', 'moreover', 'indeed', 'if', 'below', 'fire', 'bill', 'third', 'those', 'every', 'whoever', 'toward', 'serious', 'that', 'part', 'front', 'we', 'per', 'see', 'only', 'out', 'once', 'well', 'around', 'whence', 'hence', 'this', 'alone', 'thus', 'whereby', 'has', 'on', 'some', 'ten', 'until', 'due', 'take', 'whereas', 'for', 'thru', 'must', 'few', 'over', 'whether', 'others', 'four', 'please', 'whole', 'themselves', 'she', 'describe', 'via', 'wherein', 'hasnt', 'fifteen', 'were', 'formerly', 'less', 'somewhere', 'full', 'amongst', 'him', 'seems', 'sincere', 'are', 'much', 'forty', 'myself', 'which', 'already', 'without', 'bottom', 'he', 'against', 'twenty', 'might', 'sometime', 'thereby', 'etc', 'is', 'throughout', 'herself', 'sometimes', 'yourselves', 'they', 'within', 'noone', 'un', 'am', 'to', 'somehow', 'as', 'afterwards', 'me'})\n"
     ]
    }
   ],
   "source": [
    "print(ENGLISH_STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20e5ad8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of dataset before dropping the NAs: (310104, 1)\n",
      "Dimensions of dataset after dropping the NAs: (310104, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensions of dataset before dropping the NAs:\",amz.shape)\n",
    "amz = amz.dropna(subset=['status_text'])\n",
    "print(\"Dimensions of dataset after dropping the NAs:\",amz.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e86c550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3582555\n",
      "6059477\n"
     ]
    }
   ],
   "source": [
    "d=dict()\n",
    "wit=[]\n",
    "witout=[]\n",
    "total=0\n",
    "tot=0\n",
    "corpus = []\n",
    "# ENGLISH_STOP_WORDS.extend([\"changed\",\"design\"])\n",
    "stop_words = list(ENGLISH_STOP_WORDS)\n",
    "stop_words.extend(['changed','design','issue'])\n",
    "for i in range(0,len(amz)):\n",
    "    status_text = re.sub('[^a-zA-Z]', ' ', amz['status_text'][i])\n",
    "    status_text = status_text.lower()\n",
    "    status_text = status_text.split()\n",
    "    wit.append(len(status_text))\n",
    "    for word in status_text:\n",
    "        if (len(word)<6):\n",
    "            if word in d:\n",
    "                d[word] = d[word] + 1\n",
    "            else:\n",
    "                d[word] = 1\n",
    "#     ps = PorterStemmer()\n",
    "#     status_text = [ps.stem(word) for word in status_text\n",
    "#                 if not word in ENGLISH_STOP_WORDS]\n",
    "    status_text = [word for word in status_text\n",
    "                 if not word in stop_words]\n",
    "    witout.append(len(status_text))\n",
    "    \n",
    "    statustext = ' '.join(status_text) \n",
    "    corpus.append(statustext)\n",
    "# print(len(status_text))\n",
    "# print(witout)\n",
    "for ele in range(0, len(witout)):\n",
    "    total=total+witout[ele]\n",
    "    tot=tot+wit[ele]\n",
    "print(total)\n",
    "print(tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6c610d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dope = dict((k, v) for k, v in d.items() if v >= 20)\n",
    "\n",
    "# marklist = sorted(dope.items(), key=lambda x:x[1], reverse=True)\n",
    "# sortdict = dict(marklist)\n",
    "# for key,val in sortdict.items(): \n",
    "#     print(key, ' : ', val)\n",
    "# amz.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6bb3b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tes=[]\n",
    "# for key,val in sortdict.items():\n",
    "#     if key in stop_words:\n",
    "#         tes.append(key)\n",
    "#         print(key, ' : ', val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f62a157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key,val in sortdict.items():\n",
    "#     if key not in stop_words:\n",
    "#         print(key, ' : ', val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aeac9f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = len(set(sortdict.keys()) & set(stop_words))/ float(len(set(sortdict.keys()) | set(stop_words))) * 100\n",
    "# ress = (len(tes) / len(sortdict.keys())) * 100\n",
    "# resss = total / tot * 100\n",
    "# print(res)\n",
    "# print(ress)\n",
    "# print(resss)\n",
    "# # print(wit[:10])\n",
    "# # print(witout[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "643cd066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lead vehicle model year nano l v fwd cd nano l l v upgrade p',\n",
       " 'ek awaiting lab results micrographs',\n",
       " 'lab results returned reviewing jan',\n",
       " 'results lab contamination degraded materials analysis returned parts meet current specs stresses walls crack area low crack did come application loading cover additional tests ongoing determine root cause new attachment',\n",
       " 'ek running additional fea modeling looking flat skewing effects generate extra stresses causing cracks discussed tardiness closing pending hope expedient future',\n",
       " 'results presented ek low level warpage flatness stresses near crack area increase running fea higher level warpage attachment',\n",
       " 'attached d need additional flatness test results implementation date corrective action flatness end line testing production processes',\n",
       " 'attached updated d pca implemented molded covers production tools windage cut meet flatness requirements prototype parts used build additional fea analysis showed cracks result area flatness twisting loads bolt recommend pending',\n",
       " 'added final supplier d closed root cause free state flatness specification prototype molded print',\n",
       " 'closed supplier final d prototype parts corrected production parts']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed83c7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "abst=tfidf.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fb45b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shobika\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action measurements</th>\n",
       "      <th>ags</th>\n",
       "      <th>allowing</th>\n",
       "      <th>ambient</th>\n",
       "      <th>answers</th>\n",
       "      <th>armrest</th>\n",
       "      <th>awaiting feedback</th>\n",
       "      <th>baffle</th>\n",
       "      <th>ball</th>\n",
       "      <th>bar code</th>\n",
       "      <th>...</th>\n",
       "      <th>voltage</th>\n",
       "      <th>vp vp</th>\n",
       "      <th>wall</th>\n",
       "      <th>warehouse</th>\n",
       "      <th>warning</th>\n",
       "      <th>weather</th>\n",
       "      <th>welds</th>\n",
       "      <th>width</th>\n",
       "      <th>wind noise</th>\n",
       "      <th>wip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>310104.000000</td>\n",
       "      <td>310104.000000</td>\n",
       "      <td>310104.000000</td>\n",
       "      <td>310104.000000</td>\n",
       "      <td>310104.000000</td>\n",
       "      <td>310104.000000</td>\n",
       "      <td>310104.000000</td>\n",
       "      <td>310104.000000</td>\n",
       "      <td>310104.000000</td>\n",
       "      <td>310104.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>310104.000000</td>\n",
       "      <td>310104.000000</td>\n",
       "      <td>310104.000000</td>\n",
       "      <td>310104.000000</td>\n",
       "      <td>310104.000000</td>\n",
       "      <td>310104.000000</td>\n",
       "      <td>310104.000000</td>\n",
       "      <td>310104.000000</td>\n",
       "      <td>310104.000000</td>\n",
       "      <td>310104.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>0.00055</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>0.000557</td>\n",
       "      <td>0.000532</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.000584</td>\n",
       "      <td>0.000514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.007914</td>\n",
       "      <td>0.020240</td>\n",
       "      <td>0.020512</td>\n",
       "      <td>0.021651</td>\n",
       "      <td>0.019158</td>\n",
       "      <td>0.019194</td>\n",
       "      <td>0.023279</td>\n",
       "      <td>0.021058</td>\n",
       "      <td>0.019170</td>\n",
       "      <td>0.02278</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019724</td>\n",
       "      <td>0.022163</td>\n",
       "      <td>0.020752</td>\n",
       "      <td>0.022635</td>\n",
       "      <td>0.021868</td>\n",
       "      <td>0.020397</td>\n",
       "      <td>0.021417</td>\n",
       "      <td>0.019939</td>\n",
       "      <td>0.023612</td>\n",
       "      <td>0.021818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 250 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       action measurements            ags       allowing        ambient  \\\n",
       "count        310104.000000  310104.000000  310104.000000  310104.000000   \n",
       "mean              0.000133       0.000435       0.000490       0.000510   \n",
       "std               0.007914       0.020240       0.020512       0.021651   \n",
       "min               0.000000       0.000000       0.000000       0.000000   \n",
       "25%               0.000000       0.000000       0.000000       0.000000   \n",
       "50%               0.000000       0.000000       0.000000       0.000000   \n",
       "75%               0.000000       0.000000       0.000000       0.000000   \n",
       "max               1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "             answers        armrest  awaiting feedback         baffle  \\\n",
       "count  310104.000000  310104.000000      310104.000000  310104.000000   \n",
       "mean        0.000428       0.000422           0.000579       0.000475   \n",
       "std         0.019158       0.019194           0.023279       0.021058   \n",
       "min         0.000000       0.000000           0.000000       0.000000   \n",
       "25%         0.000000       0.000000           0.000000       0.000000   \n",
       "50%         0.000000       0.000000           0.000000       0.000000   \n",
       "75%         0.000000       0.000000           0.000000       0.000000   \n",
       "max         1.000000       1.000000           1.000000       1.000000   \n",
       "\n",
       "                ball      bar code  ...        voltage          vp vp  \\\n",
       "count  310104.000000  310104.00000  ...  310104.000000  310104.000000   \n",
       "mean        0.000411       0.00055  ...       0.000428       0.000509   \n",
       "std         0.019170       0.02278  ...       0.019724       0.022163   \n",
       "min         0.000000       0.00000  ...       0.000000       0.000000   \n",
       "25%         0.000000       0.00000  ...       0.000000       0.000000   \n",
       "50%         0.000000       0.00000  ...       0.000000       0.000000   \n",
       "75%         0.000000       0.00000  ...       0.000000       0.000000   \n",
       "max         1.000000       1.00000  ...       1.000000       1.000000   \n",
       "\n",
       "                wall      warehouse        warning        weather  \\\n",
       "count  310104.000000  310104.000000  310104.000000  310104.000000   \n",
       "mean        0.000483       0.000557       0.000532       0.000495   \n",
       "std         0.020752       0.022635       0.021868       0.020397   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "               welds          width     wind noise            wip  \n",
       "count  310104.000000  310104.000000  310104.000000  310104.000000  \n",
       "mean        0.000496       0.000455       0.000584       0.000514  \n",
       "std         0.021417       0.019939       0.023612       0.021818  \n",
       "min         0.000000       0.000000       0.000000       0.000000  \n",
       "25%         0.000000       0.000000       0.000000       0.000000  \n",
       "50%         0.000000       0.000000       0.000000       0.000000  \n",
       "75%         0.000000       0.000000       0.000000       0.000000  \n",
       "max         1.000000       1.000000       1.000000       1.000000  \n",
       "\n",
       "[8 rows x 250 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf=TfidfVectorizer(stop_words='english', ngram_range=(1,2), max_features=250, \n",
    "                      strip_accents='unicode', min_df=10, max_df=200)\n",
    "tfidf_relarr=tfidf.fit_transform(corpus)\n",
    "abst=pd.DataFrame(tfidf_relarr.toarray(), columns=tfidf.get_feature_names())\n",
    "abst.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1088ac83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca=PCA(n_components=10, whiten=False, random_state=42)\n",
    "abst_pca=pca.fit_transform(abst)\n",
    "after=pd.DataFrame(data=abst_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f371108",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import seaborn as sns\n",
    "inertia_list = []\n",
    "for n in range(1,100):\n",
    "    kmeans = KMeans(n_clusters=n, random_state=42)\n",
    "    kmeans.fit(after)\n",
    "    inertia_list.append(kmeans.inertia_)\n",
    "        \n",
    "    # plotting\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(111)\n",
    "sns.lineplot(y=inertia_list, x=range(1,100), ax=ax)\n",
    "ax.set_xlabel(\"Cluster\")\n",
    "ax.set_ylabel(\"Inertia\")\n",
    "ax.set_xticks(list(range(1,100)))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8b2fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "words=tfidf.get_feature_names_out()\n",
    "kmeans = KMeans(n_clusters = 20, n_init = 20) \n",
    "lables=kmeans.fit(abst)\n",
    "\n",
    "common_words = kmeans.cluster_centers_.argsort()[:,-1:-26:-1]\n",
    "for num, centroid in enumerate(common_words):\n",
    "    print(str(num) + ' : ' + ', '.join(words[word] for word in centroid))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84582dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_max = [index for index, value in enumerate(lables.labels_) if value==3]\n",
    "for rev_index in indices_max:\n",
    "    print(rev_index, str(amz.iloc[rev_index]))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c38dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(0,len(lables.labels_)):\n",
    "    dense=' '.join(corpus[i-1] for i,value in enumerate(lables.labels_) if value==x)\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color ='black',\n",
    "                      min_font_size = 7).generate(dense)\n",
    "\n",
    "    plt.figure(figsize=(10,10), facecolor=None)\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout(pad=0)\n",
    " \n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
