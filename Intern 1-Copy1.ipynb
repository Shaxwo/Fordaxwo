{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa29d9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "import random\n",
    "import re\n",
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "# !conda install wordcloud\n",
    "# import wordcloud\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c498213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>138128</th>\n",
       "      <td>Data provided to D&amp;R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62475</th>\n",
       "      <td>Team Champion is Mark Barber. Supplier Faureci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25216</th>\n",
       "      <td>Rework in AIMS 3558526 resulted in excess leng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279037</th>\n",
       "      <td>Reviewed in Tech review 5 January 2018 and acc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56844</th>\n",
       "      <td>Due to supplier could not achive current desig...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              status_text\n",
       "138128                               Data provided to D&R\n",
       "62475   Team Champion is Mark Barber. Supplier Faureci...\n",
       "25216   Rework in AIMS 3558526 resulted in excess leng...\n",
       "279037  Reviewed in Tech review 5 January 2018 and acc...\n",
       "56844   Due to supplier could not achive current desig..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amz=pd.read_csv(\"status text-2018.csv\")\n",
    "amz.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a17deb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({'former', 'two', 'perhaps', 'although', 'name', 'she', 'their', 'whatever', 'alone', 'latterly', 'can', 'in', 'most', 'off', 'bill', 'so', 'is', 'towards', 'becomes', 'sixty', 'while', 'least', 'few', 'through', 'below', 'about', 'side', 'being', 'ours', 'well', 'none', 'almost', 'serious', 'something', 'anything', 'at', 'will', 'all', 'him', 'moreover', 'sincere', 'system', 'hence', 'besides', 'nor', 'be', 'many', 'due', 'themselves', 'four', 'our', 'co', 'with', 'etc', 'both', 'himself', 'these', 'hereafter', 'everyone', 'yours', 'over', 'whoever', 'should', 'same', 'they', 'an', 'your', 'was', 'via', 'therefore', 'whereas', 're', 'had', 'hereby', 'after', 'cant', 'therein', 'where', 'nobody', 'even', 'several', 'mine', 'get', 'sometimes', 'full', 'however', 'except', 'nothing', 'someone', 'cannot', 'de', 'twenty', 'cry', 'formerly', 'whither', 'whence', 'thereafter', 'nevertheless', 'hereupon', 'fill', 'more', 'herein', 'back', 'those', 'than', 'rather', 'onto', 'thick', 'since', 'bottom', 'on', 'have', 'up', 'ten', 'also', 'once', 'among', 'each', 'call', 'sometime', 'us', 'became', 'show', 'some', 'the', 'if', 'we', 'nowhere', 'never', 'one', 'con', 'now', 'amongst', 'others', 'were', 'my', 'every', 'often', 'see', 'too', 'been', 'here', 'any', 'found', 'put', 'them', 'when', 'because', 'yet', 'between', 'you', 'beforehand', 'for', 'twelve', 'whereafter', 'beside', 'less', 'move', 'before', 'could', 'interest', 'detail', 'until', 'by', 'from', 'what', 'yourselves', 'it', 'upon', 'thereupon', 'itself', 'fifty', 'latter', 'inc', 'wherever', 'nine', 'mostly', 'such', 'everything', 'why', 'anyone', 'anyway', 'might', 'not', 'empty', 'herself', 'whose', 'me', 'who', 'six', 'per', 'behind', 'whom', 'no', 'must', 'to', 'un', 'eight', 'beyond', 'amount', 'whole', 'else', 'thence', 'do', 'though', 'couldnt', 'whereby', 'done', 'i', 'he', 'its', 'whether', 'take', 'out', 'whenever', 'ltd', 'may', 'above', 'either', 'hundred', 'anyhow', 'has', 'still', 'throughout', 'another', 'find', 'how', 'afterwards', 'myself', 'as', 'give', 'elsewhere', 'her', 'noone', 'first', 'or', 'would', 'last', 'neither', 'front', 'made', 'across', 'further', 'hasnt', 'much', 'and', 'becoming', 'always', 'amoungst', 'forty', 'of', 'meanwhile', 'within', 'wherein', 'ever', 'top', 'there', 'only', 'next', 'that', 'am', 'this', 'please', 'three', 'other', 'fire', 'five', 'own', 'then', 'become', 'somewhere', 'seems', 'somehow', 'fifteen', 'hers', 'whereupon', 'thru', 'go', 'around', 'mill', 'describe', 'but', 'everywhere', 'ourselves', 'again', 'his', 'are', 'indeed', 'seem', 'namely', 'otherwise', 'along', 'very', 'which', 'thereby', 'eg', 'part', 'anywhere', 'thin', 'down', 'already', 'into', 'seemed', 'together', 'a', 'enough', 'against', 'seeming', 'eleven', 'thus', 'without', 'yourself', 'third', 'toward', 'ie', 'during', 'keep', 'under'})\n"
     ]
    }
   ],
   "source": [
    "print(ENGLISH_STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20e5ad8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of dataset before dropping the NAs: (310104, 1)\n",
      "Dimensions of dataset after dropping the NAs: (310104, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensions of dataset before dropping the NAs:\",amz.shape)\n",
    "amz = amz.dropna(subset=['status_text'])\n",
    "print(\"Dimensions of dataset after dropping the NAs:\",amz.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e86c550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3582555\n",
      "6059477\n"
     ]
    }
   ],
   "source": [
    "d=dict()\n",
    "wit=[]\n",
    "witout=[]\n",
    "total=0\n",
    "tot=0\n",
    "corpus = []\n",
    "# ENGLISH_STOP_WORDS.extend([\"changed\",\"design\"])\n",
    "stop_words = list(ENGLISH_STOP_WORDS)\n",
    "stop_words.extend(['changed','design','issue'])\n",
    "for i in range(0,len(amz)):\n",
    "    status_text = re.sub('[^a-zA-Z]', ' ', amz['status_text'][i])\n",
    "    status_text = status_text.lower()\n",
    "    status_text = status_text.split()\n",
    "    wit.append(len(status_text))\n",
    "    for word in status_text:\n",
    "        if (len(word)<6):\n",
    "            if word in d:\n",
    "                d[word] = d[word] + 1\n",
    "            else:\n",
    "                d[word] = 1\n",
    "#     ps = PorterStemmer()\n",
    "#     status_text = [ps.stem(word) for word in status_text\n",
    "#                 if not word in ENGLISH_STOP_WORDS]\n",
    "    status_text = [word for word in status_text\n",
    "                 if not word in stop_words]\n",
    "    witout.append(len(status_text))\n",
    "    \n",
    "    statustext = ' '.join(status_text) \n",
    "    corpus.append(statustext)\n",
    "# print(len(status_text))\n",
    "# print(witout)\n",
    "for ele in range(0, len(witout)):\n",
    "    total=total+witout[ele]\n",
    "    tot=tot+wit[ele]\n",
    "print(total)\n",
    "print(tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6c610d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dope = dict((k, v) for k, v in d.items() if v >= 20)\n",
    "\n",
    "# marklist = sorted(dope.items(), key=lambda x:x[1], reverse=True)\n",
    "# sortdict = dict(marklist)\n",
    "# for key,val in sortdict.items(): \n",
    "#     print(key, ' : ', val)\n",
    "# amz.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6bb3b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tes=[]\n",
    "# for key,val in sortdict.items():\n",
    "#     if key in stop_words:\n",
    "#         tes.append(key)\n",
    "#         print(key, ' : ', val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f62a157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key,val in sortdict.items():\n",
    "#     if key not in stop_words:\n",
    "#         print(key, ' : ', val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aeac9f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = len(set(sortdict.keys()) & set(stop_words))/ float(len(set(sortdict.keys()) | set(stop_words))) * 100\n",
    "# ress = (len(tes) / len(sortdict.keys())) * 100\n",
    "# resss = total / tot * 100\n",
    "# print(res)\n",
    "# print(ress)\n",
    "# print(resss)\n",
    "# # print(wit[:10])\n",
    "# # print(witout[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "643cd066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lead vehicle model year nano l v fwd cd nano l l v upgrade p',\n",
       " 'ek awaiting lab results micrographs',\n",
       " 'lab results returned reviewing jan',\n",
       " 'results lab contamination degraded materials analysis returned parts meet current specs stresses walls crack area low crack did come application loading cover additional tests ongoing determine root cause new attachment',\n",
       " 'ek running additional fea modeling looking flat skewing effects generate extra stresses causing cracks discussed tardiness closing pending hope expedient future',\n",
       " 'results presented ek low level warpage flatness stresses near crack area increase running fea higher level warpage attachment',\n",
       " 'attached d need additional flatness test results implementation date corrective action flatness end line testing production processes',\n",
       " 'attached updated d pca implemented molded covers production tools windage cut meet flatness requirements prototype parts used build additional fea analysis showed cracks result area flatness twisting loads bolt recommend pending',\n",
       " 'added final supplier d closed root cause free state flatness specification prototype molded print',\n",
       " 'closed supplier final d prototype parts corrected production parts']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed83c7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "abst=tfidf.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fb45b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shobika\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action measurements</th>\n",
       "      <th>ags</th>\n",
       "      <th>allowing</th>\n",
       "      <th>ambient</th>\n",
       "      <th>answers</th>\n",
       "      <th>armrest</th>\n",
       "      <th>awaiting feedback</th>\n",
       "      <th>baffle</th>\n",
       "      <th>ball</th>\n",
       "      <th>bar code</th>\n",
       "      <th>...</th>\n",
       "      <th>voltage</th>\n",
       "      <th>vp vp</th>\n",
       "      <th>wall</th>\n",
       "      <th>warehouse</th>\n",
       "      <th>warning</th>\n",
       "      <th>weather</th>\n",
       "      <th>welds</th>\n",
       "      <th>width</th>\n",
       "      <th>wind noise</th>\n",
       "      <th>wip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>310104.000000</td>\n",
       "      <td>310104.000000</td>\n",
       "      <td>310104.000000</td>\n",
       "      <td>310104.000000</td>\n",
       "      <td>310104.000000</td>\n",
       "      <td>310104.000000</td>\n",
       "      <td>310104.000000</td>\n",
       "      <td>310104.000000</td>\n",
       "      <td>310104.000000</td>\n",
       "      <td>310104.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>310104.000000</td>\n",
       "      <td>310104.000000</td>\n",
       "      <td>310104.000000</td>\n",
       "      <td>310104.000000</td>\n",
       "      <td>310104.000000</td>\n",
       "      <td>310104.000000</td>\n",
       "      <td>310104.000000</td>\n",
       "      <td>310104.000000</td>\n",
       "      <td>310104.000000</td>\n",
       "      <td>310104.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>0.00055</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>0.000557</td>\n",
       "      <td>0.000532</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.000584</td>\n",
       "      <td>0.000514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.007914</td>\n",
       "      <td>0.020240</td>\n",
       "      <td>0.020512</td>\n",
       "      <td>0.021651</td>\n",
       "      <td>0.019158</td>\n",
       "      <td>0.019194</td>\n",
       "      <td>0.023279</td>\n",
       "      <td>0.021058</td>\n",
       "      <td>0.019170</td>\n",
       "      <td>0.02278</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019724</td>\n",
       "      <td>0.022163</td>\n",
       "      <td>0.020752</td>\n",
       "      <td>0.022635</td>\n",
       "      <td>0.021868</td>\n",
       "      <td>0.020397</td>\n",
       "      <td>0.021417</td>\n",
       "      <td>0.019939</td>\n",
       "      <td>0.023612</td>\n",
       "      <td>0.021818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 250 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       action measurements            ags       allowing        ambient  \\\n",
       "count        310104.000000  310104.000000  310104.000000  310104.000000   \n",
       "mean              0.000133       0.000435       0.000490       0.000510   \n",
       "std               0.007914       0.020240       0.020512       0.021651   \n",
       "min               0.000000       0.000000       0.000000       0.000000   \n",
       "25%               0.000000       0.000000       0.000000       0.000000   \n",
       "50%               0.000000       0.000000       0.000000       0.000000   \n",
       "75%               0.000000       0.000000       0.000000       0.000000   \n",
       "max               1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "             answers        armrest  awaiting feedback         baffle  \\\n",
       "count  310104.000000  310104.000000      310104.000000  310104.000000   \n",
       "mean        0.000428       0.000422           0.000579       0.000475   \n",
       "std         0.019158       0.019194           0.023279       0.021058   \n",
       "min         0.000000       0.000000           0.000000       0.000000   \n",
       "25%         0.000000       0.000000           0.000000       0.000000   \n",
       "50%         0.000000       0.000000           0.000000       0.000000   \n",
       "75%         0.000000       0.000000           0.000000       0.000000   \n",
       "max         1.000000       1.000000           1.000000       1.000000   \n",
       "\n",
       "                ball      bar code  ...        voltage          vp vp  \\\n",
       "count  310104.000000  310104.00000  ...  310104.000000  310104.000000   \n",
       "mean        0.000411       0.00055  ...       0.000428       0.000509   \n",
       "std         0.019170       0.02278  ...       0.019724       0.022163   \n",
       "min         0.000000       0.00000  ...       0.000000       0.000000   \n",
       "25%         0.000000       0.00000  ...       0.000000       0.000000   \n",
       "50%         0.000000       0.00000  ...       0.000000       0.000000   \n",
       "75%         0.000000       0.00000  ...       0.000000       0.000000   \n",
       "max         1.000000       1.00000  ...       1.000000       1.000000   \n",
       "\n",
       "                wall      warehouse        warning        weather  \\\n",
       "count  310104.000000  310104.000000  310104.000000  310104.000000   \n",
       "mean        0.000483       0.000557       0.000532       0.000495   \n",
       "std         0.020752       0.022635       0.021868       0.020397   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "               welds          width     wind noise            wip  \n",
       "count  310104.000000  310104.000000  310104.000000  310104.000000  \n",
       "mean        0.000496       0.000455       0.000584       0.000514  \n",
       "std         0.021417       0.019939       0.023612       0.021818  \n",
       "min         0.000000       0.000000       0.000000       0.000000  \n",
       "25%         0.000000       0.000000       0.000000       0.000000  \n",
       "50%         0.000000       0.000000       0.000000       0.000000  \n",
       "75%         0.000000       0.000000       0.000000       0.000000  \n",
       "max         1.000000       1.000000       1.000000       1.000000  \n",
       "\n",
       "[8 rows x 250 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf=TfidfVectorizer(stop_words='english', ngram_range=(1,2), max_features=250, \n",
    "                      strip_accents='unicode', min_df=10, max_df=200)\n",
    "tfidf_relarr=tfidf.fit_transform(corpus)\n",
    "abst=pd.DataFrame(tfidf_relarr.toarray(), columns=tfidf.get_feature_names())\n",
    "abst.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1088ac83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca=PCA(n_components=10, whiten=False, random_state=42)\n",
    "abst_pca=pca.fit_transform(abst)\n",
    "after=pd.DataFrame(data=abst_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a055b85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import seaborn as sns\n",
    "inertia_list = []\n",
    "for n in range(1,100):\n",
    "    kmeans = KMeans(n_clusters=n, random_state=42)\n",
    "    kmeans.fit(after)\n",
    "    inertia_list.append(kmeans.inertia_)\n",
    "        \n",
    "    # plotting\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(111)\n",
    "sns.lineplot(y=inertia_list, x=range(1,100), ax=ax)\n",
    "ax.set_xlabel(\"Cluster\")\n",
    "ax.set_ylabel(\"Inertia\")\n",
    "ax.set_xticks(list(range(1,100)))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e4db9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=20, random_state=42)\n",
    "labels = kmeans.fit_predict(after)\n",
    "df_abstracts_labeled = amz.copy()\n",
    "df_abstracts_labeled[\"cluster\"] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cc2608",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_abstracts_labeled[df_abstracts_labeled[\"cluster\"] == 75][[\"staus_text\", \"cluster\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09083146",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import DBSCAN\n",
    "def findOptimalEps(n_neighbors, data):\n",
    "    '''\n",
    "    function to find optimal eps distance when using DBSCAN; based on this article: https://towardsdatascience.com/machine-learning-clustering-dbscan-determine-the-optimal-value-for-epsilon-eps-python-example-3100091cfbc\n",
    "    '''\n",
    "    neigh = NearestNeighbors(n_neighbors=n_neighbors)\n",
    "    nbrs = neigh.fit(data)\n",
    "    distances, indices = nbrs.kneighbors(data)\n",
    "    distances = np.sort(distances, axis=0)\n",
    "    distances = distances[:,1]\n",
    "    plt.plot(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15e55f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "findOptimalEps(2, abst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf06276",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(eps=0.6, metric=\"euclidean\")\n",
    "dbscan_labels = dbscan.fit_predict(after)\n",
    "df_abstracts_dbscan = amz.copy()\n",
    "df_abstracts_dbscan[\"cluster\"] = dbscan_labels\n",
    "df_abstracts_dbscan[\"cluster\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d220f4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_abstracts_dbscan[df_abstracts_dbscan[\"cluster\"] == 1][[\"status_text\", \"cluster\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08517437",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
